# ğŸ¯ Automatic Tokenizer Generator for Low-Resource Languages 
[![Technical Report](https://img.shields.io/badge/Technical%20Report-PDF-blue)](https://github.com/rarahnamoun/Tokenizer-Generator/blob/main/report.pdf)
<br/>
A self-adapting tokenization system that automatically generates and implements optimal tokenization strategies based on input text characteristics.
## âš¡ Overview
This project introduces an innovative language-independent system that automatically generates and implements tokenizer algorithms based on input text characteristics. While specifically validated on Persian as a low-resource language case study, the system can adapt to various languages and text challenges through its automatic generation capabilities.

## ğŸš€ Key Features
- **Automatic Tokenizer Generation**: System analyzes input text and generates optimal tokenization strategies
- **Language Independence**: Works across different languages with focus on low-resource languages
- **Challenge-Adaptive Processing**: Automatically handles:
  - âš™ï¸ Syntax-based text errors
  - ğŸ”„ Random space insertion/deletion
  - ğŸ”— Connected text (no spaces)
  - ğŸ§© Complex semantic structures
  - ğŸŒ Multi-lingual input
- **Multiple Tokenization Strategies**: Automatically implements and optimizes:
  - ğŸ“ Word-based tokenization
  - ğŸ“„ Sentence-based tokenization
  - ğŸ”¤ Character-based tokenization
  - âš¡ Regex-based tokenization
  - ğŸ” Context-sensitive tokenization
  - ğŸ“Š Frequency-based tokenization

## ğŸ“ˆ Performance Across Challenges

### 1. ğŸ’« Standard Text Processing
- **Accuracy**: 99%
- **Top Performers**: 
  - Auto-generated basic word tokenizer
  - Adaptive whitespace tokenizer
  - Dynamic n-gram tokenizers

### 2. ğŸ”— Connected Text (No Spaces)
- **Accuracy**: 94%
- **Best Solutions**:
  - Auto-generated maximum matching tokenizer
  - Adaptive space normalization dictionary

### 3. âš¡ Random Space Handling
- **Accuracy**: 84%
- **Features**:
  - Automated statistical model generation
  - Dynamic space normalization
  - Adaptive pattern recognition

### 4. ğŸ¯ Complex Text Scenarios
- **Accuracy**: 89%
- **Handles**:
  - ğŸ’¬ Informal text
  - âœï¸ Misspellings
  - ğŸŒ Multi-lingual content
  - ğŸ”£ Special characters


## ğŸ“¦ Requirements
- Python 3.x
- Jupyter Notebook

4. ğŸŒ Petrov, A., La Malfa, E., Torr, P., Bibi, A. (2024). Language model tokenizers introduce unfairness between languages.

## ğŸ“Š Detailed Report
For a comprehensive analysis of the system's architecture, methodology, and results, please see our report
